[FILE LOCS]
vocab_dir = ./vocab/data
dirty_dataset_dir = ./datasets/dirty
clean_dataset_dir = ./datasets/clean
preprocessed_dataset = ./datasets/processed/dataset.data
model_load = ./models/model
model_save = ./models/model

[MODEL INFO]
embedding_size = 64
state_size = 1024
gru_depth = 4
dropout_keep_prob = 0.9

[TRAIN INFO]
batch_size = 75
lambda = 0

[VOCAB INFO]
zero_mask = 0
unk_token = 1
start_token = 2
end_token = 3
div_token = 4

[DATA INFO]
min_cutoffs = 200000
start_num = 452
